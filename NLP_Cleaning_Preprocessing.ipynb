{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646a6627",
   "metadata": {},
   "source": [
    "# NLP - Cleaning and Preprocessing Text Data of User Reviews in AppStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195abc5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d49a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "# natural language toolkit\n",
    "import nltk\n",
    "# string for punctuation list\n",
    "import string\n",
    "# to remove links, numbers\n",
    "import re\n",
    "# to get stopwords from smart stopword list link\n",
    "from urllib.request import urlopen\n",
    "# wordnet for part of the speech\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "# Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#Stemmers\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1121a885",
   "metadata": {},
   "source": [
    "##  CSV Read and DataFrame Creation\n",
    "\n",
    "We load a CSV file, create a DataFrame, and verify its shape. Initially, we have a dataset with 3097 rows and 16 columns, where each row represents a distinct reviews posted on AppStore for 10 different apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b88c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print(data.shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bdd78b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3097, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>wc</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>thumb?</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>aapp_name</th>\n",
       "      <th>aacat1</th>\n",
       "      <th>inex1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>972</td>\n",
       "      <td>gp:AOqpTOEtDRJ3jrXbHFtJDkV6M20O2WZMvMoHEprDcCM...</td>\n",
       "      <td>Debbie Peach</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
       "      <td>Need more notice when Alexa is going to add co...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>2.2.342851.0</td>\n",
       "      <td>2020-06-20 3:52:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alexa</td>\n",
       "      <td>accessibility</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>959</td>\n",
       "      <td>gp:AOqpTOGZhKglDGI88-WwwUTIW0lAJ829T3aMFxy3vB3...</td>\n",
       "      <td>Glenn McMillan</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
       "      <td>I have given up on this app, it is constantly ...</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2.280247.0</td>\n",
       "      <td>2019-08-15 1:32:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alexa</td>\n",
       "      <td>accountability</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1055</td>\n",
       "      <td>gp:AOqpTOEYd-V6GjkM2N14YmvR5HkL9IGR1KrcIP9lCwS...</td>\n",
       "      <td>Holly Baker</td>\n",
       "      <td>https://play-lh.googleusercontent.com/-gQkg1A5...</td>\n",
       "      <td>Im addicted and didnt even want an Alexa. She ...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2.319280.0</td>\n",
       "      <td>2020-02-25 13:51:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alexa</td>\n",
       "      <td>Addiction</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1071</td>\n",
       "      <td>gp:AOqpTOEI7VftVQUfMCXv2CeTOIXKmubxMYrO2iKL2V6...</td>\n",
       "      <td>DreLisa Richmond</td>\n",
       "      <td>https://play-lh.googleusercontent.com/-w_zy3dM...</td>\n",
       "      <td>Must repeat request more than I would like. Fr...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-08 15:07:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alexa</td>\n",
       "      <td>Addiction</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1074</td>\n",
       "      <td>gp:AOqpTOFxOeKALhwBlDR_N-uMFW7h2So_kBlU8NDxDfN...</td>\n",
       "      <td>James Besel</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
       "      <td>I love all of my devices. I am kind of addicte...</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2.372932.0</td>\n",
       "      <td>2020-11-19 23:07:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alexa</td>\n",
       "      <td>Addiction</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>562</td>\n",
       "      <td>gp:AOqpTOHeODykxpgVuJDCiyWm5MOu8EKeDx5iRRaB6Th...</td>\n",
       "      <td>Chadwick Smith</td>\n",
       "      <td>https://play-lh.googleusercontent.com/-bV_Dipz...</td>\n",
       "      <td>I don't like it at all i feel unsafe using thi...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-06 9:05:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zoom</td>\n",
       "      <td>safety</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>630</td>\n",
       "      <td>gp:AOqpTOEUav74SI4pHVyOAkUt1Tm3brQu_EiiBONo9oJ...</td>\n",
       "      <td>Cheryl-Lee Borzsony</td>\n",
       "      <td>https://play-lh.googleusercontent.com/-CfYxSTM...</td>\n",
       "      <td>No experience other than being scammed</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>5.4.1.453</td>\n",
       "      <td>2020-11-07 17:35:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zoom</td>\n",
       "      <td>scam</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>634</td>\n",
       "      <td>gp:AOqpTOEjhIgP4HN8EYJza2wvtnPtHoD1WBI6H3REetG...</td>\n",
       "      <td>Skye pa</td>\n",
       "      <td>https://play-lh.googleusercontent.com/-eCn8M2B...</td>\n",
       "      <td>Good way to get scammed and credit info stolen...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>5.4.4.615</td>\n",
       "      <td>2020-11-23 18:05:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zoom</td>\n",
       "      <td>scam</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>2982</td>\n",
       "      <td>gp:AOqpTOFZ42Ov8J_LzmCJ6RFyKKTtf_C2pBEGpwZzlWL...</td>\n",
       "      <td>Amjad Al Taleb</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
       "      <td>Battery killer!</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>5.3.52883.0928</td>\n",
       "      <td>2020-10-03 10:55:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zoom</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>2958</td>\n",
       "      <td>gp:AOqpTOFdb_CpL4cH9UEvW0ETPHai73pxN0nywD4f_QZ...</td>\n",
       "      <td>a b</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
       "      <td>I don't recommend this app to anyone. Upon sig...</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>5.3.52883.0928</td>\n",
       "      <td>2020-10-10 20:53:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zoom</td>\n",
       "      <td>transparency</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3097 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           reviewId  \\\n",
       "0      972  gp:AOqpTOEtDRJ3jrXbHFtJDkV6M20O2WZMvMoHEprDcCM...   \n",
       "1      959  gp:AOqpTOGZhKglDGI88-WwwUTIW0lAJ829T3aMFxy3vB3...   \n",
       "2     1055  gp:AOqpTOEYd-V6GjkM2N14YmvR5HkL9IGR1KrcIP9lCwS...   \n",
       "3     1071  gp:AOqpTOEI7VftVQUfMCXv2CeTOIXKmubxMYrO2iKL2V6...   \n",
       "4     1074  gp:AOqpTOFxOeKALhwBlDR_N-uMFW7h2So_kBlU8NDxDfN...   \n",
       "...    ...                                                ...   \n",
       "3092   562  gp:AOqpTOHeODykxpgVuJDCiyWm5MOu8EKeDx5iRRaB6Th...   \n",
       "3093   630  gp:AOqpTOEUav74SI4pHVyOAkUt1Tm3brQu_EiiBONo9oJ...   \n",
       "3094   634  gp:AOqpTOEjhIgP4HN8EYJza2wvtnPtHoD1WBI6H3REetG...   \n",
       "3095  2982  gp:AOqpTOFZ42Ov8J_LzmCJ6RFyKKTtf_C2pBEGpwZzlWL...   \n",
       "3096  2958  gp:AOqpTOFdb_CpL4cH9UEvW0ETPHai73pxN0nywD4f_QZ...   \n",
       "\n",
       "                 userName                                          userImage  \\\n",
       "0            Debbie Peach  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
       "1          Glenn McMillan  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
       "2             Holly Baker  https://play-lh.googleusercontent.com/-gQkg1A5...   \n",
       "3        DreLisa Richmond  https://play-lh.googleusercontent.com/-w_zy3dM...   \n",
       "4             James Besel  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
       "...                   ...                                                ...   \n",
       "3092       Chadwick Smith  https://play-lh.googleusercontent.com/-bV_Dipz...   \n",
       "3093  Cheryl-Lee Borzsony  https://play-lh.googleusercontent.com/-CfYxSTM...   \n",
       "3094              Skye pa  https://play-lh.googleusercontent.com/-eCn8M2B...   \n",
       "3095       Amjad Al Taleb  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
       "3096                  a b  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
       "\n",
       "                                                content   wc  score  \\\n",
       "0     Need more notice when Alexa is going to add co...   18      4   \n",
       "1     I have given up on this app, it is constantly ...  138      1   \n",
       "2     Im addicted and didnt even want an Alexa. She ...   18      5   \n",
       "3     Must repeat request more than I would like. Fr...   15      3   \n",
       "4     I love all of my devices. I am kind of addicte...   56      4   \n",
       "...                                                 ...  ...    ...   \n",
       "3092  I don't like it at all i feel unsafe using thi...   12      1   \n",
       "3093             No experience other than being scammed    6      5   \n",
       "3094  Good way to get scammed and credit info stolen...   16      1   \n",
       "3095                                    Battery killer!    2      2   \n",
       "3096  I don't recommend this app to anyone. Upon sig...   54      1   \n",
       "\n",
       "      thumbsUpCount thumb? reviewCreatedVersion                   at  \\\n",
       "0                 0  FALSE         2.2.342851.0   2020-06-20 3:52:26   \n",
       "1                 2      1         2.2.280247.0   2019-08-15 1:32:36   \n",
       "2                 1      1         2.2.319280.0  2020-02-25 13:51:42   \n",
       "3                 1      1                  NaN  2020-05-08 15:07:48   \n",
       "4                 7      1         2.2.372932.0  2020-11-19 23:07:48   \n",
       "...             ...    ...                  ...                  ...   \n",
       "3092              0  FALSE                  NaN   2020-09-06 9:05:54   \n",
       "3093              0  FALSE            5.4.1.453  2020-11-07 17:35:09   \n",
       "3094              0  FALSE            5.4.4.615  2020-11-23 18:05:10   \n",
       "3095              0  FALSE       5.3.52883.0928  2020-10-03 10:55:05   \n",
       "3096              0  FALSE       5.3.52883.0928  2020-10-10 20:53:43   \n",
       "\n",
       "     replyContent repliedAt aapp_name          aacat1     inex1  \n",
       "0             NaN       NaN     alexa   accessibility  internal  \n",
       "1             NaN       NaN     alexa  accountability  internal  \n",
       "2             NaN       NaN     alexa       Addiction  internal  \n",
       "3             NaN       NaN     alexa       Addiction  internal  \n",
       "4             NaN       NaN     alexa       Addiction  internal  \n",
       "...           ...       ...       ...             ...       ...  \n",
       "3092          NaN       NaN      zoom          safety  internal  \n",
       "3093          NaN       NaN      zoom            scam  internal  \n",
       "3094          NaN       NaN      zoom            scam  internal  \n",
       "3095          NaN       NaN      zoom  sustainability  internal  \n",
       "3096          NaN       NaN      zoom    transparency  internal  \n",
       "\n",
       "[3097 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"final_annotations.csv\"\n",
    "df = get_data(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec113fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apps: alexa, facebook, googlehome, instagram, linkedin, tiktok, uber, vinted, youtube, zoom\n",
      "\n",
      "Raised Ethical Concerns:  accessibility, accountability, Addiction, discrimination, none, privacy, safety, scam, sustainability, censorship, Cyberbullying/toxicity, harmful advertising, identity theft, inappropriate content, Noise, spreading false information, transparency, Unethical company, Content theft, cyberbullying, content theft\n"
     ]
    }
   ],
   "source": [
    "# Get unique values of apps and raised ethical concerns of reviews\n",
    "apps = df['aapp_name'].unique()\n",
    "print('Apps:', ', '.join(apps))\n",
    "\n",
    "concerns = df['aacat1'].unique()\n",
    "print('\\nRaised Ethical Concerns: ', ', '.join(concerns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61fa21",
   "metadata": {},
   "source": [
    "## Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ed5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLink(text):\n",
    "    no_link = ' '.join(re.sub(\"(w+://S+)\", \" \", text).split())\n",
    "    return no_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7910add6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Need more notice when Alexa is going to add co...\n",
       "1       I have given up on this app, it is constantly ...\n",
       "2       Im addicted and didnt even want an Alexa. She ...\n",
       "3       Must repeat request more than I would like. Fr...\n",
       "4       I love all of my devices. I am kind of addicte...\n",
       "                              ...                        \n",
       "3092    I don't like it at all i feel unsafe using thi...\n",
       "3093               No experience other than being scammed\n",
       "3094    Good way to get scammed and credit info stolen...\n",
       "3095                                      Battery killer!\n",
       "3096    I don't recommend this app to anyone. Upon sig...\n",
       "Name: clean_content, Length: 3097, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_content'] = df['content'].apply(lambda x: removeLink(x))\n",
    "df['clean_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7aa09",
   "metadata": {},
   "source": [
    "## Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0c309f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNumber(text):\n",
    "    return ' '.join(re.sub(r'[0-9]',' ', text).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbac9ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Need more notice when Alexa is going to add co...\n",
       "1       I have given up on this app, it is constantly ...\n",
       "2       Im addicted and didnt even want an Alexa. She ...\n",
       "3       Must repeat request more than I would like. Fr...\n",
       "4       I love all of my devices. I am kind of addicte...\n",
       "                              ...                        \n",
       "3092    I don't like it at all i feel unsafe using thi...\n",
       "3093               No experience other than being scammed\n",
       "3094    Good way to get scammed and credit info stolen...\n",
       "3095                                      Battery killer!\n",
       "3096    I don't recommend this app to anyone. Upon sig...\n",
       "Name: clean_content, Length: 3097, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_content'] = df['clean_content'].apply(lambda x: removeNumber(x))\n",
    "\n",
    "df['clean_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8de3bd",
   "metadata": {},
   "source": [
    "## Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e287c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(text):\n",
    "    return text.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede80646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I can't comment anymore why is it limited I'm so sad I wanna delete it but I'm dead to my uncle if I do thatðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­\"\n",
      " \"I can't comment anymore why is it limited I'm so sad I wanna delete it but I'm dead to my uncle if I do that\"]\n"
     ]
    }
   ],
   "source": [
    "df['clean_content'] = df['clean_content'].apply(lambda x: deEmojify(x))\n",
    "\n",
    "#df['clean_content']\n",
    "print(df.loc[450, ['content','clean_content']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132acc9d",
   "metadata": {},
   "source": [
    "## Converting all characters to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738592f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       need more notice when alexa is going to add co...\n",
       "1       i have given up on this app, it is constantly ...\n",
       "2       im addicted and didnt even want an alexa. she ...\n",
       "3       must repeat request more than i would like. fr...\n",
       "4       i love all of my devices. i am kind of addicte...\n",
       "                              ...                        \n",
       "3092    i don't like it at all i feel unsafe using thi...\n",
       "3093               no experience other than being scammed\n",
       "3094    good way to get scammed and credit info stolen...\n",
       "3095                                      battery killer!\n",
       "3096    i don't recommend this app to anyone. upon sig...\n",
       "Name: clean_content, Length: 3097, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_content'] = df['clean_content'].apply(lambda x: x.lower())\n",
    "df['clean_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6523e",
   "metadata": {},
   "source": [
    "## Remove stopwords\n",
    "* nltk.corpus.stopwords.words('english') could be also used. However, it contains 179, whereas smart stopword list does 571 words, including â€˜iâ€™, â€˜meâ€™, â€˜myâ€™, â€˜myselfâ€™, â€˜weâ€™, â€˜youâ€™, â€˜heâ€™, â€˜hisâ€™, for instance. \n",
    "* stpwrd is here extended with app names that are mentioned in the reviews as well since they are going to be included in every reviews that belong to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1288830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stopwords():\n",
    "    stpwrd_url = \"http://www.ai.mit.edu/projects/jmlr/papers/volume5/lewis04a/a11-smart-stop-list/english.stop\"\n",
    "    response = urlopen(stpwrd_url)\n",
    "    stpwrds = response.read().decode('utf-8').replace(\"\\n\", \" \").split()\n",
    "    new_stopwords = [\"app\", \"alexa\", \"facebook\", \n",
    "                     \"googlehome\", \"instagram\", \"linkedin\", \"tiktok\", \"tik\", \"tok\", \"uber\"]\n",
    "    stpwrds.extend(new_stopwords)\n",
    "    return stpwrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268d0ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stpwrds):\n",
    "    text = text.split(\" \")\n",
    "    words = [w for w in text if w not in stpwrds]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cce9b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "stpwrds = generate_stopwords()\n",
    "df['clean_content'] = df['clean_content'].apply(lambda x: remove_stopwords(x, stpwrds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb757e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I can't comment anymore why is it limited I'm so sad I wanna delete it but I'm dead to my uncle if I do thatðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­\"\n",
      " 'comment anymore limited sad wanna delete dead uncle']\n"
     ]
    }
   ],
   "source": [
    "#df['clean_content']\n",
    "print(df.loc[450, ['content','clean_content']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f24bef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               notice add comments command hard hearing.\n",
       "1       app, constantly offline multiple devices sign ...\n",
       "2       im addicted didnt alexa. memory companion im a...\n",
       "3       repeat request like. frustrating times. conven...\n",
       "4       love devices. kind addicted them. stay organiz...\n",
       "                              ...                        \n",
       "3092                                          feel unsafe\n",
       "3093                                   experience scammed\n",
       "3094     good scammed credit info stolen. horrible peril.\n",
       "3095                                      battery killer!\n",
       "3096    recommend anyone. signing found delete account...\n",
       "Name: clean_content, Length: 3097, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63be0b",
   "metadata": {},
   "source": [
    "## Remove punctuation\n",
    "The process of punctuation elimination involves iterating through the series using list comprehension and preserving all elements that do not exist in the __string.punctuation__ list. This list, imported at the beginning using __import string__, comprises all punctuation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba2c78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunctuation(text):\n",
    "    no_punc = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7f8f7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                notice add comments command hard hearing\n",
       "1       app constantly offline multiple devices sign s...\n",
       "2       im addicted didnt alexa memory companion im al...\n",
       "3       repeat request like frustrating times convenie...\n",
       "4       love devices kind addicted them stay organized...\n",
       "                              ...                        \n",
       "3092                                          feel unsafe\n",
       "3093                                   experience scammed\n",
       "3094       good scammed credit info stolen horrible peril\n",
       "3095                                       battery killer\n",
       "3096    recommend anyone signing found delete account ...\n",
       "Name: clean_content, Length: 3097, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_content'] = df['clean_content'].apply(lambda x: removePunctuation(x))\n",
    "df['clean_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c9ef0",
   "metadata": {},
   "source": [
    "## Tokenizing words\n",
    "\n",
    "* __RegexpTokenizer__ is a function that is used to break down a string into smaller substrings based on a specified regular expression pattern. The selected pattern splits up by spaces that are not attached to a digit as numbers are already cleaned from reviews.\n",
    "* __discard\\_empty__ is set to True. It ensures that any empty tokens produced by the tokenizer are removed from the resulting output. \n",
    "(see in https://www.nltk.org/_modules/nltk/tokenize/regexp.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e007d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+', discard_empty=True)\n",
    "df['clean_content'] = df['clean_content'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9e5b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [notice, add, comments, command, hard, hearing]\n",
      "1       [app, constantly, offline, multiple, devices, ...\n",
      "2       [im, addicted, didnt, alexa, memory, companion...\n",
      "3       [repeat, request, like, frustrating, times, co...\n",
      "4       [love, devices, kind, addicted, them, stay, or...\n",
      "                              ...                        \n",
      "3092                                       [feel, unsafe]\n",
      "3093                                [experience, scammed]\n",
      "3094    [good, scammed, credit, info, stolen, horrible...\n",
      "3095                                    [battery, killer]\n",
      "3096    [recommend, anyone, signing, found, delete, ac...\n",
      "Name: clean_content, Length: 3097, dtype: object\n",
      "\n",
      "One particular review:\n",
      "[\"I can't comment anymore why is it limited I'm so sad I wanna delete it but I'm dead to my uncle if I do thatðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­\"\n",
      " list(['comment', 'anymore', 'limited', 'sad', 'wanna', 'delete', 'dead', 'uncle'])]\n"
     ]
    }
   ],
   "source": [
    "print(df['clean_content'])\n",
    "print(\"\\nOne particular review:\")\n",
    "print(df.loc[450, ['content','clean_content']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a914234",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatizing\n",
    "\n",
    "The Stemming and Lemmatizing methods are used in natural language processing to simplify words by converting them to their base or root form. During the process, they both are explored and evaluated to determine the most suitable one based on the requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459112b",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "To stem the review texts, them ost common method, PorterStemmer, from nltk library is used.\n",
    "Stemming is a relatively more proactive approach that involves removing prefixes and/or suffixes from words based on commonly observed patterns. While it can be useful in certain cases, it is not always reliable as the resulting word may lose its original meaning by becoming too generic or root-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9923de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemmer(text, stemmer):\n",
    "    stem_text = [stemmer.stem(i) for i in text]\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b055c2f",
   "metadata": {},
   "source": [
    "### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2be7c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "df['clean_content_porter'] = df['clean_content'].apply(lambda x: word_stemmer(x, porter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e6803",
   "metadata": {},
   "source": [
    "### SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c490dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(language='english')\n",
    "df['clean_content_snowball'] = df['clean_content'].apply(lambda x: word_stemmer(x, snowball))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e631c91",
   "metadata": {},
   "source": [
    "### LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "160c1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster = LancasterStemmer()\n",
    "df['clean_content_lancaster'] = df['clean_content'].apply(lambda x: word_stemmer(x, lancaster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf792cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One particular review:\n",
      "[list(['comment', 'anymore', 'limited', 'sad', 'wanna', 'delete', 'dead', 'uncle'])\n",
      " list(['comment', 'anymor', 'limit', 'sad', 'wanna', 'delet', 'dead', 'uncl'])\n",
      " list(['comment', 'anymor', 'limit', 'sad', 'wanna', 'delet', 'dead', 'uncl'])\n",
      " list(['com', 'anym', 'limit', 'sad', 'wann', 'delet', 'dead', 'unc'])]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOne particular review:\")\n",
    "print(df.loc[450, ['clean_content',\n",
    "                   'clean_content_porter', \n",
    "                   'clean_content_snowball', \n",
    "                   'clean_content_lancaster']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7045094",
   "metadata": {},
   "source": [
    "## Lemmatizing\n",
    "To lemmatize the review texts, WordNetLemmatizer from nltk library is used.\n",
    "\n",
    "Lemmatizing maps words to their base or dictionary form by considering their part of speech. Unlike stemming, lemmatization consistently returns valid words that can be found in a dictionary. The goal of lemmatization algorithms is to accurately reduce inflected words, ensuring the association of the base word with the language is preserved.\n",
    "\n",
    "To normalize a word, it is necessary to determine its part of speech. During this process, the rules for normalization will vary depending on the specific part of speech of the word. The Wordnet Lemmatizer allows you to specify a specific part of speech (POS) tag. Part-of-speech constants are: \n",
    "ADJ = a'\n",
    "ADJ_SAT = 's'\n",
    "ADV = 'r'\n",
    "NOUN = 'n'\n",
    "VERB = 'v'\n",
    "\n",
    "In this case, we set the tag to 'v' which represents 'verb' and 'a' which represents 'adjective'. Typically, this POS tag is used for lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7efdab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_speech(word):\n",
    "    probable_part_of_speech = wordnet.synsets(word)\n",
    "    pos_counts = Counter()\n",
    "    #pos_counts[\"n\"] = len([item for item in probable_part_of_speech if item.pos() == \"n\"])\n",
    "    pos_counts[\"v\"] = len([item for item in probable_part_of_speech if item.pos() == \"v\"])\n",
    "    pos_counts[\"a\"] = len([item for item in probable_part_of_speech if item.pos() == \"a\"])  \n",
    "    #pos_counts[\"r\"] = len([item for item in probable_part_of_speech if item.pos() == \"r\"])\n",
    "\n",
    "    most_likely_part_of_speech = pos_counts.most_common(1)[0][0]\n",
    "    return most_likely_part_of_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11e59c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text, lemmatizer):\n",
    "    lem_text = [lemmatizer.lemmatize(i, get_part_of_speech(i)) for i in text]\n",
    "    return lem_text\n",
    "lemmatizer =  WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d60dbbc",
   "metadata": {},
   "source": [
    "#### Test case\n",
    "In this example, strengths and weaknesses of using pos tags can be tested. \n",
    "\n",
    "By considering only verb and adjective tags, 'worst' is transformed to 'bad' and 'addicted' is transformed to 'addict'. However, 'rating' is changed to 'rat'.\n",
    "\n",
    "On the other hand, if noun tag is used (it can tested by commenting/uncommenting the the tag in __get_part_of_speech()__, the past tense is preserved, but 'rating' is not converted to 'rat'.\n",
    "\n",
    "This scenario exemplifies the well-known No Free Lunch Theorem, where we must carefully evaluate the pros and cons of each approach and make a decision based on the specific advantages and disadvantages they offer.\n",
    "\n",
    "Considering the amount of reviews, it is decided to use only verbs and adjectives to reduce the number of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30b36f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worst', 'was', 'bad', 'are', 'addicted', 'scammed', 'hearing', 'swimming', 'rating']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bad', 'be', 'bad', 'be', 'addict', 'scammed', 'hear', 'swim', 'rat']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['worst', 'was', 'bad', 'are', 'addicted', 'scammed', 'hearing', 'swimming', 'rating']\n",
    "print(test)\n",
    "word_lemmatizer(test,lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72f146de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_content'] = df['clean_content'].apply(lambda x: word_lemmatizer(x, lemmatizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5664b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                content  \\\n",
      "0     Need more notice when Alexa is going to add co...   \n",
      "1     I have given up on this app, it is constantly ...   \n",
      "2     Im addicted and didnt even want an Alexa. She ...   \n",
      "3     Must repeat request more than I would like. Fr...   \n",
      "4     I love all of my devices. I am kind of addicte...   \n",
      "...                                                 ...   \n",
      "3092  I don't like it at all i feel unsafe using thi...   \n",
      "3093             No experience other than being scammed   \n",
      "3094  Good way to get scammed and credit info stolen...   \n",
      "3095                                    Battery killer!   \n",
      "3096  I don't recommend this app to anyone. Upon sig...   \n",
      "\n",
      "                                          clean_content  \n",
      "0           [notice, add, comment, command, hard, hear]  \n",
      "1     [app, constantly, offline, multiple, devices, ...  \n",
      "2     [im, addict, didnt, alexa, memory, companion, ...  \n",
      "3     [repeat, request, like, frustrate, time, conve...  \n",
      "4     [love, devices, kind, addict, them, stay, orga...  \n",
      "...                                                 ...  \n",
      "3092                                     [feel, unsafe]  \n",
      "3093                              [experience, scammed]  \n",
      "3094  [good, scammed, credit, info, steal, horrible,...  \n",
      "3095                                  [battery, killer]  \n",
      "3096  [recommend, anyone, sign, find, delete, accoun...  \n",
      "\n",
      "[3097 rows x 2 columns]\n",
      "\n",
      "One particular review:\n",
      "[\"Need more notice when Alexa is going to add comments after a command as I'm hard of hearing.\"\n",
      " list(['notice', 'add', 'comment', 'command', 'hard', 'hear'])]\n"
     ]
    }
   ],
   "source": [
    "print(df[['content','clean_content']])\n",
    "print(\"\\nOne particular review:\")\n",
    "print(df.loc[0, ['content','clean_content']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9e398",
   "metadata": {},
   "source": [
    "### Stemmer vs Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f1a4958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw review:  I can't comment anymore why is it limited I'm so sad I wanna delete it but I'm dead to my uncle if I do thatðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­\n",
      "lemmatized:  ['comment', 'anymore', 'limit', 'sad', 'wanna', 'delete', 'dead', 'uncle']\n",
      "stemmed with porter:  ['comment', 'anymor', 'limit', 'sad', 'wanna', 'delet', 'dead', 'uncl']\n"
     ]
    }
   ],
   "source": [
    "print('raw review: ', df.loc[450,'content'])\n",
    "print('lemmatized: ', df.loc[450,'clean_content'])\n",
    "print('stemmed with porter: ', df.loc[450,'clean_content_porter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce910f",
   "metadata": {},
   "source": [
    "### Including the app names and etchical concerns in the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb7b2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "concern = True\n",
    "app = True\n",
    "if concern:\n",
    "    for index, row in df.iterrows():\n",
    "        row[\"clean_content\"].append(row[\"aacat1\"])\n",
    "if app:\n",
    "    for index, row in df.iterrows():\n",
    "        row[\"clean_content\"].append(row[\"aapp_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "582cf7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['notice',\n",
       "  'add',\n",
       "  'comment',\n",
       "  'command',\n",
       "  'hard',\n",
       "  'hear',\n",
       "  'accessibility',\n",
       "  'alexa'],\n",
       " ['app',\n",
       "  'constantly',\n",
       "  'offline',\n",
       "  'multiple',\n",
       "  'devices',\n",
       "  'sign',\n",
       "  'sign',\n",
       "  'app',\n",
       "  'tell',\n",
       "  'echo',\n",
       "  'line',\n",
       "  'devices',\n",
       "  'connect',\n",
       "  'work',\n",
       "  'correctly',\n",
       "  'reset',\n",
       "  'echo',\n",
       "  'multiple',\n",
       "  'time',\n",
       "  'create',\n",
       "  'account',\n",
       "  'reinstall',\n",
       "  'multiple',\n",
       "  'devices',\n",
       "  'result',\n",
       "  'account',\n",
       "  'constantly',\n",
       "  'line',\n",
       "  'numerous',\n",
       "  'email',\n",
       "  'desk',\n",
       "  'reply',\n",
       "  'account',\n",
       "  'server',\n",
       "  'issue',\n",
       "  'amazon',\n",
       "  'honest',\n",
       "  'users',\n",
       "  'echo',\n",
       "  'device',\n",
       "  'work',\n",
       "  'fine',\n",
       "  'capable',\n",
       "  'voice',\n",
       "  'control',\n",
       "  'light',\n",
       "  'replace',\n",
       "  'competitors',\n",
       "  'product',\n",
       "  'stage',\n",
       "  'recommend',\n",
       "  'product',\n",
       "  'anyone',\n",
       "  'accountability',\n",
       "  'alexa'],\n",
       " ['im',\n",
       "  'addict',\n",
       "  'didnt',\n",
       "  'alexa',\n",
       "  'memory',\n",
       "  'companion',\n",
       "  'im',\n",
       "  'alone',\n",
       "  'lol',\n",
       "  'Addiction',\n",
       "  'alexa']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_list = df[\"clean_content\"].tolist()\n",
    "corpus_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96c23eb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'corpus_list' (list)\n"
     ]
    }
   ],
   "source": [
    "%store corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060461e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
